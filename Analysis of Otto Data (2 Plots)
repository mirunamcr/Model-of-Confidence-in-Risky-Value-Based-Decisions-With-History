# Nov 20eth Meeting
# Doing 2 new plots, one to check within, one to check across pop

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import minimize
from scipy.special import expit
from scipy.stats import pearsonr

# Settings
DATA_PATH = "/Users/miru/Documents/PSYC 385 Thesis/Phase2_data (Raw Otto).csv"
ALLOWED_P = {0.5, 0.9, 1.0}
BOUNDS = [(0.01, 5.0), (0.0, 2.0), (0.1, 20.0)]   # alpha, beta (>=0), mu
N_REPS = 100
MIN_TRIALS = 50        
RNG_SEED = 0

# Load data 
def load_phase2_df(path=DATA_PATH):
    cols = ['PID', 'P_Gamble', 'A_Gamble', 'A_Certain', 'Gamble']
    df = pd.read_csv(path, usecols=cols)
    df['P_Gamble'] = pd.to_numeric(df['P_Gamble'], errors='coerce')
    df = df[df['P_Gamble'].isin(ALLOWED_P)].reset_index(drop=True)
    return df

df = load_phase2_df()

# model functions 
def subjective_values(p, A_g, A_c, alpha, beta):
    SV_r = (p ** (1 - beta)) * (A_g ** alpha)
    SV_c = (A_c ** alpha)
    return SV_r, SV_c

def nll_joint(params, p, A_g, A_c, choices):
    alpha, beta, mu = params
    SV_r, SV_c = subjective_values(p, A_g, A_c, alpha, beta)
    dSV = SV_r - SV_c
    p_gamble = expit(mu * dSV)
    p_gamble = np.clip(p_gamble, 1e-9, 1 - 1e-9)
    return -np.sum(choices * np.log(p_gamble) + (1 - choices) * np.log(1 - p_gamble))

def fit_safe(p_sub, Ag_sub, Ac_sub, choices_sub, x0=(1.0, 0.0, 1.0), bounds=BOUNDS):
    try:
        res = minimize(nll_joint, x0=x0, args=(p_sub, Ag_sub, Ac_sub, choices_sub),
                       bounds=bounds, method="L-BFGS-B", options={"maxiter":1000})
        if res.success and np.all(np.isfinite(res.x)):
            return np.array(res.x, dtype=float)
    except Exception:
        pass
    return np.array([np.nan, np.nan, np.nan], dtype=float)

rng = np.random.default_rng(RNG_SEED)

# collect per-participant mean-half parameters
pids = []
alpha_half1_means = []
alpha_half2_means = []
beta_half1_means = []
beta_half2_means = []
mu_half1_means = []
mu_half2_means = []

for pid, sub in df.groupby("PID"):
    n = len(sub)
    if n < MIN_TRIALS:
        continue

    p_all = sub["P_Gamble"].values
    Ag_all = sub["A_Gamble"].values
    Ac_all = sub["A_Certain"].values
    choices_all = sub["Gamble"].astype(int).values

    a1_list, a2_list = [], []
    b1_list, b2_list = [], []
    m1_list, m2_list = [], []

    for _ in range(N_REPS):
        perm = rng.permutation(n)
        half = n // 2
        if half < 2:
            break
        idx1 = perm[:half]
        idx2 = perm[half:half+half]

        r1 = fit_safe(p_all[idx1], Ag_all[idx1], Ac_all[idx1], choices_all[idx1])
        r2 = fit_safe(p_all[idx2], Ag_all[idx2], Ac_all[idx2], choices_all[idx2])

        a1_list.append(r1[0]); b1_list.append(r1[1]); m1_list.append(r1[2])
        a2_list.append(r2[0]); b2_list.append(r2[1]); m2_list.append(r2[2])

    # compute mean across repeats (ignore NaNs)
    a1m = np.nanmean(a1_list) if np.any(np.isfinite(a1_list)) else np.nan
    a2m = np.nanmean(a2_list) if np.any(np.isfinite(a2_list)) else np.nan
    b1m = np.nanmean(b1_list) if np.any(np.isfinite(b1_list)) else np.nan
    b2m = np.nanmean(b2_list) if np.any(np.isfinite(b2_list)) else np.nan
    m1m = np.nanmean(m1_list) if np.any(np.isfinite(m1_list)) else np.nan
    m2m = np.nanmean(m2_list) if np.any(np.isfinite(m2_list)) else np.nan

    # require that both halves produced at least one finite fit for this participant
    if not (np.isfinite(a1m) and np.isfinite(a2m)):
        continue

    pids.append(pid)
    alpha_half1_means.append(a1m); alpha_half2_means.append(a2m)
    beta_half1_means.append(b1m);  beta_half2_means.append(b2m)
    mu_half1_means.append(m1m);    mu_half2_means.append(m2m)

# assemble dataframe
summary = pd.DataFrame({
    "PID": pids,
    "alpha_h1": alpha_half1_means, "alpha_h2": alpha_half2_means,
    "beta_h1":  beta_half1_means,  "beta_h2":  beta_half2_means,
    "mu_h1":    mu_half1_means,    "mu_h2":    mu_half2_means
})

# plotting helper
def scatter_and_corr(x, y, xlabel, ylabel, title):
    mask = np.isfinite(x) & np.isfinite(y)
    if mask.sum() < 2:
        print("Not enough data to compute correlation for", title)
        return
    r, pval = pearsonr(x[mask], y[mask])
    fig, ax = plt.subplots(figsize=(6,6))
    ax.scatter(x[mask], y[mask], s=40, edgecolor='k', alpha=0.8)
    mn = min(np.nanmin(x[mask]), np.nanmin(y[mask])); mx = max(np.nanmax(x[mask]), np.nanmax(y[mask]))
    pad = 0.05 * (mx - mn) if mx>mn else 0.1
    ax.plot([mn-pad, mx+pad], [mn-pad, mx+pad], color='gray', linestyle='--')
    ax.set_xlabel(xlabel); ax.set_ylabel(ylabel)
    ax.set_title(f"{title}\nPearson r={r:.3f}, p={pval:.3g}")
    ax.grid(alpha=0.12)
    plt.tight_layout()
    plt.show()
    print(f"{title} â€” r={r:.4f}, p={pval:.4g}, n={mask.sum()}")

# make three plots (alpha, beta, mu)
scatter_and_corr(summary["alpha_h1"].values, summary["alpha_h2"].values, "Alpha (Half 1)", "Alpha (Half 2)", "Alpha: Half1 vs Half2")
scatter_and_corr(summary["beta_h1"].values,  summary["beta_h2"].values,  "Beta (Half 1)",  "Beta (Half 2)",  "Beta: Half1 vs Half2")
scatter_and_corr(summary["mu_h1"].values,    summary["mu_h2"].values,    "Mu (Half 1)",    "Mu (Half 2)",    "Mu: Half1 vs Half2")

# save summary
summary.to_csv("/Users/miru/Documents/PSYC 385 Thesis/split_half_param_means_per_pid.csv", index=False)
#_________________________________________________________
# PLOT 2: Distribution of Split-Half Correlations (Histogram)

# compute split-half correlations for alpha, beta, mu
alpha_half_corrs = []
beta_half_corrs = []
mu_half_corrs = []

for pid, sub in df.groupby("PID"):
    n = len(sub)
    if n < MIN_TRIALS:
        continue

    p_all = sub["P_Gamble"].values
    Ag_all = sub["A_Gamble"].values
    Ac_all = sub["A_Certain"].values
    choices_all = sub["Gamble"].astype(int).values

    a1_list, a2_list = [], []
    b1_list, b2_list = [], []
    m1_list, m2_list = [], []

    for _ in range(N_REPS):
        perm = rng.permutation(n)
        half = n // 2
        if half < 2:
            break
        idx1 = perm[:half]
        idx2 = perm[half:half+half]

        r1 = fit_safe(p_all[idx1], Ag_all[idx1], Ac_all[idx1], choices_all[idx1])
        r2 = fit_safe(p_all[idx2], Ag_all[idx2], Ac_all[idx2], choices_all[idx2])

        a1_list.append(r1[0]); b1_list.append(r1[1]); m1_list.append(r1[2])
        a2_list.append(r2[0]); b2_list.append(r2[1]); m2_list.append(r2[2])

    # compute mean across repeats & ignore NaNs 
    a1m = np.nanmean(a1_list) if np.any(np.isfinite(a1_list)) else np.nan
    a2m = np.nanmean(a2_list) if np.any(np.isfinite(a2_list)) else np.nan
    b1m = np.nanmean(b1_list) if np.any(np.isfinite(b1_list)) else np.nan
    b2m = np.nanmean(b2_list) if np.any(np.isfinite(b2_list)) else np.nan
    m1m = np.nanmean(m1_list) if np.any(np.isfinite(m1_list)) else np.nan
    m2m = np.nanmean(m2_list) if np.any(np.isfinite(m2_list)) else np.nan

    # both halves must have at least one finite fit for that participant
    if not (np.isfinite(a1m) and np.isfinite(a2m)): 
        continue

    # compute correlations between halves
    if np.isfinite(a1m) and np.isfinite(a2m):
        alpha_half_corrs.append(pearsonr(a1_list, a2_list)[0])
    if np.isfinite(b1m) and np.isfinite(b2m):
        beta_half_corrs.append(pearsonr(b1_list, b2_list)[0])
    if np.isfinite(m1m) and np.isfinite(m2m):
        mu_half_corrs.append(pearsonr(m1_list, m2_list)[0])

# plot histograms of correlations
fig, axs = plt.subplots(3, 1, figsize=(8, 12), sharex=True)

axs[0].hist(alpha_half_corrs, bins=np.linspace(-1, 1, 21), color='skyblue', edgecolor='k', alpha=0.7)
axs[0].set_ylabel("Frequency")
axs[0].set_title("Distribution of Split-Half Correlations (Alpha)")

axs[1].hist(beta_half_corrs, bins=np.linspace(-1, 1, 21), color='salmon', edgecolor='k', alpha=0.7)
axs[1].set_ylabel("Frequency")
axs[1].set_title("Distribution of Split-Half Correlations (Beta)")

axs[2].hist(mu_half_corrs, bins=np.linspace(-1, 1, 21), color='lightgreen', edgecolor='k', alpha=0.7)
axs[2].set_xlabel("Correlation Coefficient")
axs[2].set_ylabel("Frequency")
axs[2].set_title("Distribution of Split-Half Correlations (Mu)")

plt.tight_layout()
plt.show()

# save correlation data
correlation_summary = pd.DataFrame({
    "alpha_half_corrs": alpha_half_corrs,
    "beta_half_corrs": beta_half_corrs,
    "mu_half_corrs": mu_half_corrs
})
correlation_summary.to_csv("/Users/miru/Documents/PSYC 385 Thesis/split_half_correlations.csv", index=False)

